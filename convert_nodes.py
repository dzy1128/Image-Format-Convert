import torch
import numpy as np
from PIL import Image
import io


class ImageFormatConverter:
    """
    ComfyUIèŠ‚ç‚¹ï¼šå›¾ç‰‡æ ¼å¼è½¬æ¢å™¨
    æ”¯æŒå°†è¾“å…¥å›¾ç‰‡è½¬æ¢ä¸ºæŒ‡å®šçš„ç›®æ ‡æ ¼å¼
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),  # è¾“å…¥å›¾ç‰‡ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰
                "output_format": (["PNG", "JPEG", "WEBP", "BMP", "TIFF"],),  # è¾“å‡ºæ ¼å¼é€‰æ‹©
                "quality": ("INT", {
                    "default": 95,
                    "min": 1,
                    "max": 100,
                    "step": 1,
                    "display": "number"
                }),  # å›¾ç‰‡è´¨é‡ï¼ˆä¸»è¦ç”¨äºJPEGå’ŒWEBPï¼‰
            },
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("converted_images",)
    FUNCTION = "convert_format"
    CATEGORY = "image/format"
    
    def convert_format(self, images, output_format, quality):
        """
        è½¬æ¢å›¾ç‰‡æ ¼å¼
        
        Args:
            images: è¾“å…¥å›¾ç‰‡å¼ é‡ (batch_size, height, width, channels)
            output_format: ç›®æ ‡æ ¼å¼
            quality: å›¾ç‰‡è´¨é‡
            
        Returns:
            è½¬æ¢åçš„å›¾ç‰‡å¼ é‡
        """
        # ç¡®ä¿è¾“å…¥æ˜¯torchå¼ é‡
        if not isinstance(images, torch.Tensor):
            images = torch.tensor(images)
        
        # è·å–æ‰¹é‡å¤§å°
        batch_size = images.shape[0] if len(images.shape) == 4 else 1
        if len(images.shape) == 3:
            images = images.unsqueeze(0)
        
        converted_images = []
        
        for i in range(batch_size):
            # æå–å•å¼ å›¾ç‰‡
            image_tensor = images[i]
            
            # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾ç‰‡
            # ComfyUIçš„å›¾ç‰‡å¼ é‡æ ¼å¼é€šå¸¸æ˜¯ (H, W, C)ï¼Œå€¼åŸŸåœ¨0-1ä¹‹é—´
            if image_tensor.max() <= 1.0:
                image_array = (image_tensor * 255).clamp(0, 255).cpu().numpy().astype(np.uint8)
            else:
                image_array = image_tensor.clamp(0, 255).cpu().numpy().astype(np.uint8)
            
            pil_image = Image.fromarray(image_array)
            
            # å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
            if output_format == "JPEG":
                # JPEGä¸æ”¯æŒé€æ˜åº¦ï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
                if pil_image.mode in ('RGBA', 'LA', 'P'):
                    # åˆ›å»ºç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', pil_image.size, (255, 255, 255))
                    if pil_image.mode == 'P':
                        pil_image = pil_image.convert('RGBA')
                    background.paste(pil_image, mask=pil_image.split()[-1] if pil_image.mode == 'RGBA' else None)
                    pil_image = background
                else:
                    pil_image = pil_image.convert('RGB')
            
            elif output_format == "PNG":
                # PNGæ”¯æŒé€æ˜åº¦ï¼Œä¿æŒåŸæœ‰æ¨¡å¼æˆ–è½¬æ¢ä¸ºRGBA
                if pil_image.mode not in ('RGBA', 'RGB', 'L'):
                    pil_image = pil_image.convert('RGBA')
            
            elif output_format == "WEBP":
                # WebPæ”¯æŒé€æ˜åº¦
                if pil_image.mode == 'P':
                    pil_image = pil_image.convert('RGBA')
            
            elif output_format == "BMP":
                # BMPä¸æ”¯æŒé€æ˜åº¦
                if pil_image.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', pil_image.size, (255, 255, 255))
                    if pil_image.mode == 'P':
                        pil_image = pil_image.convert('RGBA')
                    if pil_image.mode == 'RGBA':
                        background.paste(pil_image, mask=pil_image.split()[-1])
                    pil_image = background
                else:
                    pil_image = pil_image.convert('RGB')
            
            elif output_format == "TIFF":
                # TIFFæ”¯æŒå¤šç§æ¨¡å¼
                if pil_image.mode == 'P':
                    pil_image = pil_image.convert('RGBA')
            
            # å°†PILå›¾ç‰‡è½¬æ¢å›å­—èŠ‚æµå†è½¬æ¢å›å¼ é‡ï¼Œæ¨¡æ‹Ÿæ ¼å¼è½¬æ¢è¿‡ç¨‹
            buffer = io.BytesIO()
            
            # æ ¹æ®æ ¼å¼è®¾ç½®ä¿å­˜å‚æ•°
            save_kwargs = {}
            if output_format in ["JPEG", "WEBP"]:
                save_kwargs['quality'] = quality
                save_kwargs['optimize'] = True
            elif output_format == "PNG":
                save_kwargs['optimize'] = True
            
            pil_image.save(buffer, format=output_format, **save_kwargs)
            buffer.seek(0)
            
            # é‡æ–°åŠ è½½å›¾ç‰‡ä»¥ç¡®ä¿æ ¼å¼è½¬æ¢ç”Ÿæ•ˆ
            converted_pil = Image.open(buffer)
            
            # è½¬æ¢å›å¼ é‡æ ¼å¼
            if converted_pil.mode == 'L':
                # ç°åº¦å›¾è½¬æ¢ä¸ºRGB
                converted_pil = converted_pil.convert('RGB')
            elif converted_pil.mode == 'RGBA':
                # ä¿æŒRGBAæ ¼å¼
                pass
            elif converted_pil.mode == 'RGB':
                # ä¿æŒRGBæ ¼å¼
                pass
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            converted_array = np.array(converted_pil).astype(np.float32) / 255.0
            
            # ç¡®ä¿æ˜¯3é€šé“æˆ–4é€šé“
            if len(converted_array.shape) == 2:
                # ç°åº¦å›¾ï¼Œè½¬æ¢ä¸ºRGB
                converted_array = np.stack([converted_array] * 3, axis=-1)
            elif converted_array.shape[-1] == 4:
                # RGBAï¼Œä¿æŒ4é€šé“
                pass
            elif converted_array.shape[-1] == 3:
                # RGBï¼Œä¿æŒ3é€šé“
                pass
            
            # å¦‚æœåŸå›¾æ˜¯3é€šé“ï¼Œè¾“å‡ºä¹Ÿä¿æŒ3é€šé“
            if image_tensor.shape[-1] == 3 and converted_array.shape[-1] == 4:
                converted_array = converted_array[:, :, :3]
            
            converted_tensor = torch.from_numpy(converted_array)
            converted_images.append(converted_tensor)
            
            buffer.close()
        
        # å †å æ‰€æœ‰è½¬æ¢åçš„å›¾ç‰‡
        result = torch.stack(converted_images, dim=0)
        
        return (result,)


class ImageFormatInfo:
    """
    å›¾ç‰‡æ ¼å¼ä¿¡æ¯æ˜¾ç¤ºèŠ‚ç‚¹
    æ˜¾ç¤ºè¾“å…¥å›¾ç‰‡çš„æ ¼å¼ä¿¡æ¯
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
            },
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("format_info",)
    FUNCTION = "get_format_info"
    CATEGORY = "image/format"
    OUTPUT_NODE = True
    
    def get_format_info(self, images):
        """
        è·å–è¯¦ç»†çš„å›¾ç‰‡æ ¼å¼ä¿¡æ¯
        """
        if not isinstance(images, torch.Tensor):
            images = torch.tensor(images)
        
        batch_size = images.shape[0] if len(images.shape) == 4 else 1
        if len(images.shape) == 3:
            images = images.unsqueeze(0)
        
        info_list = []
        
        for i in range(batch_size):
            image_tensor = images[i]
            height, width, channels = image_tensor.shape
            
            # åŸºæœ¬ä¿¡æ¯
            info_dict = {
                "å›¾ç‰‡åºå·": i + 1,
                "å°ºå¯¸": f"{width} Ã— {height}",
                "æ€»åƒç´ ": width * height,
                "é€šé“æ•°": channels,
                "æ•°æ®ç±»å‹": str(image_tensor.dtype),
                "è®¾å¤‡": str(image_tensor.device)
            }
            
            # åˆ¤æ–­è‰²å½©æ ¼å¼ç±»å‹
            if channels == 1:
                color_format = "ç°åº¦å›¾ (Grayscale)"
                color_space = "L"
            elif channels == 3:
                color_format = "å½©è‰²å›¾ (RGB)"
                color_space = "RGB"
            elif channels == 4:
                color_format = "å¸¦é€æ˜åº¦å½©è‰²å›¾ (RGBA)"
                color_space = "RGBA"
            else:
                color_format = f"å¤šé€šé“å›¾åƒ ({channels}é€šé“)"
                color_space = f"{channels}C"
            
            info_dict["è‰²å½©æ ¼å¼"] = color_format
            info_dict["è‰²å½©ç©ºé—´"] = color_space
            
            # æ•°å€¼èŒƒå›´åˆ†æ
            min_val = float(image_tensor.min())
            max_val = float(image_tensor.max())
            mean_val = float(image_tensor.mean())
            
            info_dict["æ•°å€¼èŒƒå›´"] = f"{min_val:.3f} ~ {max_val:.3f}"
            info_dict["å¹³å‡å€¼"] = f"{mean_val:.3f}"
            
            # åˆ¤æ–­æ•°å€¼ç±»å‹
            if min_val >= 0 and max_val <= 1.0:
                value_type = "æ ‡å‡†åŒ– (0-1)"
            elif min_val >= 0 and max_val <= 255:
                value_type = "8ä½æ•´æ•° (0-255)"
            else:
                value_type = "è‡ªå®šä¹‰èŒƒå›´"
            
            info_dict["æ•°å€¼ç±»å‹"] = value_type
            
            # é€æ˜åº¦åˆ†æï¼ˆä»…é€‚ç”¨äºRGBAï¼‰
            if channels == 4:
                alpha_channel = image_tensor[:, :, 3]
                alpha_min = float(alpha_channel.min())
                alpha_max = float(alpha_channel.max())
                alpha_mean = float(alpha_channel.mean())
                
                if alpha_min == alpha_max == 1.0:
                    transparency_info = "å®Œå…¨ä¸é€æ˜"
                elif alpha_min == alpha_max == 0.0:
                    transparency_info = "å®Œå…¨é€æ˜"
                elif alpha_min == 0.0 and alpha_max == 1.0:
                    transparency_info = f"éƒ¨åˆ†é€æ˜ (å¹³å‡: {alpha_mean:.3f})"
                else:
                    transparency_info = f"é€æ˜åº¦: {alpha_min:.3f} ~ {alpha_max:.3f} (å¹³å‡: {alpha_mean:.3f})"
                
                info_dict["é€æ˜åº¦"] = transparency_info
            
            # å†…å­˜å ç”¨
            memory_mb = image_tensor.element_size() * image_tensor.nelement() / (1024 * 1024)
            info_dict["å†…å­˜å ç”¨"] = f"{memory_mb:.2f} MB"
            
            # æ¨èçš„è¾“å‡ºæ ¼å¼
            recommended_formats = []
            if channels == 1:
                recommended_formats = ["PNG", "JPEG", "TIFF"]
            elif channels == 3:
                recommended_formats = ["JPEG", "PNG", "WEBP"]
            elif channels == 4:
                recommended_formats = ["PNG", "WEBP", "TIFF"]
            
            info_dict["æ¨èæ ¼å¼"] = ", ".join(recommended_formats)
            
            # æ ¼å¼åŒ–è¾“å‡º
            info_lines = [f"ğŸ“· å›¾ç‰‡ {i+1} è¯¦ç»†ä¿¡æ¯:"]
            info_lines.append("=" * 30)
            
            for key, value in info_dict.items():
                if key != "å›¾ç‰‡åºå·":
                    info_lines.append(f"{key}: {value}")
            
            info_lines.append("")  # ç©ºè¡Œåˆ†éš”
            
            info_list.extend(info_lines)
        
        # æ‰¹é‡æ€»ç»“ä¿¡æ¯
        if batch_size > 1:
            summary_lines = [
                f"ğŸ“Š æ‰¹é‡å¤„ç†æ€»ç»“:",
                "=" * 30,
                f"å›¾ç‰‡æ€»æ•°: {batch_size}",
                f"æ€»å†…å­˜å ç”¨: {sum(img.element_size() * img.nelement() for img in images) / (1024 * 1024):.2f} MB"
            ]
            
            # æ£€æŸ¥æ ¼å¼ä¸€è‡´æ€§
            first_shape = images[0].shape
            consistent_format = all(img.shape == first_shape for img in images)
            summary_lines.append(f"æ ¼å¼ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if consistent_format else 'âŒ ä¸ä¸€è‡´'}")
            
            info_list.extend(summary_lines)
        
        result_info = "\n".join(info_list)
        print(f"\nğŸ” å›¾ç‰‡æ ¼å¼åˆ†æç»“æœ:\n{result_info}")
        
        return (result_info,)


class ImageBatchCombiner:
    """
    å›¾ç‰‡æ‰¹é‡ç»„åˆèŠ‚ç‚¹
    å°†æœ€å¤š5å¼ å›¾ç‰‡ç»„åˆæˆä¸€ä¸ªbatchï¼Œä¿æŒåŸå§‹å°ºå¯¸
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image1": ("IMAGE",),  # ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå¿…é€‰ï¼‰
            },
            "optional": {
                "image2": ("IMAGE",),  # ç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
                "image3": ("IMAGE",),  # ç¬¬ä¸‰å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
                "image4": ("IMAGE",),  # ç¬¬å››å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
                "image5": ("IMAGE",),  # ç¬¬äº”å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
            },
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image_batch",)
    FUNCTION = "combine_images"
    CATEGORY = "image/batch"
    
    def combine_images(self, image1, image2=None, image3=None, image4=None, image5=None):
        """
        å°†è¾“å…¥çš„å›¾ç‰‡ç»„åˆæˆä¸€ä¸ªbatch
        
        Args:
            image1: ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå¿…é€‰ï¼‰
            image2-image5: å…¶ä»–å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç»„åˆåçš„å›¾ç‰‡batch
        """
        # æ”¶é›†æ‰€æœ‰éç©ºçš„å›¾ç‰‡
        images_list = [image1]
        
        for img in [image2, image3, image4, image5]:
            if img is not None:
                images_list.append(img)
        
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½æ˜¯torchå¼ é‡
        processed_images = []
        for img in images_list:
            if not isinstance(img, torch.Tensor):
                img = torch.tensor(img)
            
            # å¦‚æœæ˜¯å•å¼ å›¾ç‰‡ï¼ˆ3ç»´ï¼‰ï¼Œæ·»åŠ batchç»´åº¦
            if len(img.shape) == 3:
                img = img.unsqueeze(0)
            
            # å¦‚æœè¾“å…¥æœ¬èº«å·²ç»æ˜¯batchï¼Œéœ€è¦åˆ†è§£
            for i in range(img.shape[0]):
                processed_images.append(img[i])
        
        # æ£€æŸ¥æ‰€æœ‰å›¾ç‰‡çš„é€šé“æ•°æ˜¯å¦ä¸€è‡´
        channels = processed_images[0].shape[-1]
        for i, img in enumerate(processed_images):
            if img.shape[-1] != channels:
                # å¦‚æœé€šé“æ•°ä¸ä¸€è‡´ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºRGBï¼ˆ3é€šé“ï¼‰
                if img.shape[-1] == 1:  # ç°åº¦å›¾è½¬RGB
                    img = img.repeat(1, 1, 3)
                elif img.shape[-1] == 4:  # RGBAè½¬RGBï¼ˆå»é™¤alphaé€šé“ï¼‰
                    img = img[:, :, :3]
                processed_images[i] = img
        
        # é‡æ–°æ£€æŸ¥é€šé“æ•°
        channels = processed_images[0].shape[-1]
        final_images = []
        
        for img in processed_images:
            # ç¡®ä¿æ‰€æœ‰å›¾ç‰‡é€šé“æ•°ä¸€è‡´
            if img.shape[-1] != channels:
                if channels == 3 and img.shape[-1] == 1:
                    img = img.repeat(1, 1, 3)
                elif channels == 3 and img.shape[-1] == 4:
                    img = img[:, :, :3]
            final_images.append(img)
        
        # ç»„åˆæˆbatch - ä¿æŒæ¯å¼ å›¾ç‰‡çš„åŸå§‹å°ºå¯¸
        result_batch = torch.stack(final_images, dim=0)
        
        print(f"ğŸ”„ å›¾ç‰‡æ‰¹é‡ç»„åˆå®Œæˆ:")
        print(f"   è¾“å…¥å›¾ç‰‡æ•°é‡: {len(final_images)}")
        print(f"   è¾“å‡ºbatchå½¢çŠ¶: {result_batch.shape}")
        print(f"   å„å›¾ç‰‡å°ºå¯¸:")
        for i, img in enumerate(final_images):
            print(f"     å›¾ç‰‡{i+1}: {img.shape[1]}Ã—{img.shape[0]}Ã—{img.shape[2]}")
        
        return (result_batch,)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImageFormatConverter": ImageFormatConverter,
    "ImageFormatInfo": ImageFormatInfo,
    "ImageBatchCombiner": ImageBatchCombiner,
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°
NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageFormatConverter": "Image Format Converter",
    "ImageFormatInfo": "Image Format Info",
    "ImageBatchCombiner": "Image Batch Combiner",
}
